var suggestions=document.getElementById('suggestions'),userinput=document.getElementById('userinput');document.addEventListener('keydown',inputFocus);function inputFocus(a){a.keyCode===191&&(a.preventDefault(),userinput.focus()),a.keyCode===27&&(userinput.blur(),suggestions.classList.add('d-none'))}document.addEventListener('click',function(a){var b=suggestions.contains(a.target);b||suggestions.classList.add('d-none')}),document.addEventListener('keydown',suggestionFocus);function suggestionFocus(b){const d=suggestions.querySelectorAll('a'),e=[...d],a=e.indexOf(document.activeElement);let c=0;b.keyCode===38?(b.preventDefault(),c=a>0?a-1:0,d[c].focus()):b.keyCode===40&&(b.preventDefault(),c=a+1<e.length?a+1:a,d[c].focus())}(function(){var b=new FlexSearch({preset:'score',cache:!0,doc:{id:'id',field:['title','description','content'],store:['href','title','description']}}),c=[{id:0,href:"/blog/trivy-intro/",title:"Container Scanning with Trivy in Jenkins",description:"Container security scanning in Jenkins CI with Trivy",content:'\u003cp\u003eYou can identify and address the security vulnerabilities earlier in the software development life-cycle if you integrate a scanner in the continuous integration (CI) pipelines. There are multiple open-source and commercial tools out there that can scan the applications and containers. When comparing these tools, we consider the following aspects:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eEasier integration with the pipelines through plugins, scripts, or API calls.\u003c/li\u003e\n\u003cli\u003eFaster, ideally synchronous execution. It should not hold up the build pipeline.\u003c/li\u003e\n\u003cli\u003eAbility to easily ignore false positives, unfixable, and realized vulnerabilities.\u003c/li\u003e\n\u003cli\u003eAudit report access from the pipeline and roll-up at the organizational level.\u003c/li\u003e\n\u003cli\u003eAbility to run tests from developer machines easily\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eCI pipeline integration is often just one part of an enterprise security toolchain. Tools like AquaSecurity, Prisma, Snyk, and others provide additional features such as periodic re-scanning, run-time monitoring, alerting, and a centralized dashboard for the security teams. In this blog post, however, we will look into \u003ca href="https://github.com/aquasecurity/trivy"\u003eTrivy\u003c/a\u003e. Trivy is an open-source scanner from the AquaSecurity team that can scan container images or filesystem paths for vulnerable operating system packages or application dependencies.\u003c/p\u003e\n\u003cfigure class="wide"\u003e\n  \u003cimg class="img-fluid lazyload blur-up" data-sizes="auto" src="/blog/trivy-intro/trivy-highlight_hueaa312ec703a544d1f6222b224c34b98_621057_20x0_resize_box_2.png" data-srcset="https://foreops.com/blog/trivy-intro/trivy-highlight_hueaa312ec703a544d1f6222b224c34b98_621057_900x0_resize_box_2.png 900w,https://foreops.com/blog/trivy-intro/trivy-highlight_hueaa312ec703a544d1f6222b224c34b98_621057_800x0_resize_box_2.png 800w,https://foreops.com/blog/trivy-intro/trivy-highlight_hueaa312ec703a544d1f6222b224c34b98_621057_700x0_resize_box_2.png 700w,https://foreops.com/blog/trivy-intro/trivy-highlight_hueaa312ec703a544d1f6222b224c34b98_621057_600x0_resize_box_2.png 600w,https://foreops.com/blog/trivy-intro/trivy-highlight_hueaa312ec703a544d1f6222b224c34b98_621057_500x0_resize_box_2.png 500w" width="813" height="450" alt="Trivy: A simple and comprehensive vulernerability"\u003e\n  \u003cnoscript\u003e\u003cimg class="img-fluid" sizes="100vw" srcset="https://foreops.com/blog/trivy-intro/trivy-highlight_hueaa312ec703a544d1f6222b224c34b98_621057_900x0_resize_box_2.png 900w,https://foreops.com/blog/trivy-intro/trivy-highlight_hueaa312ec703a544d1f6222b224c34b98_621057_800x0_resize_box_2.png 800w,https://foreops.com/blog/trivy-intro/trivy-highlight_hueaa312ec703a544d1f6222b224c34b98_621057_700x0_resize_box_2.png 700w,https://foreops.com/blog/trivy-intro/trivy-highlight_hueaa312ec703a544d1f6222b224c34b98_621057_600x0_resize_box_2.png 600w,https://foreops.com/blog/trivy-intro/trivy-highlight_hueaa312ec703a544d1f6222b224c34b98_621057_500x0_resize_box_2.png 500w" src="/blog/trivy-intro/trivy-highlight.png" width="813" height="450" alt="Trivy: A simple and comprehensive vulernerability"\u003e\u003c/noscript\u003e\n  \n\u003c/figure\u003e\n\n\u003cp\u003eLet\u0026rsquo;s review our scanner selection criteria with Trivy.\u003c/p\u003e\n\u003ch3 id="getting-started"\u003eGetting Started\u003c/h3\u003e\n\u003cp\u003eLet\u0026rsquo;s download \u003ccode\u003etrivy\u003c/code\u003e CLI and test it on our local machine:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003e$ curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin v0.18.3\naquasecurity/trivy info checking GitHub for tag \'v0.18.3\'\naquasecurity/trivy info found version: 0.18.3 for v0.18.3/macOS/64bit\naquasecurity/trivy info installed /usr/local/bin/trivy\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThere are several binaries available for \u003ccode\u003e*-nix\u003c/code\u003e based systems. If you can\u0026rsquo;t find the right binary, you have an option to use the \u003ca href="https://hub.docker.com/r/aquasec/trivy"\u003e\u003ccode\u003eaquasec/trivy\u003c/code\u003e\u003c/a\u003e container instead. First, let\u0026rsquo;s take a quick look at the CLI.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003e$ trivy --help\nNAME:\n   trivy - A simple and comprehensive vulnerability scanner for containers\n\nUSAGE:\n   trivy [global options] command [command options] target\n\nVERSION:\n   0.18.3\n\nCOMMANDS:\n   image, i          scan an image\n   filesystem, fs    scan local filesystem\n   repository, repo  scan remote repository\n   client, c         client mode\n   server, s         server mode\n   plugin, p         manage plugins\n   help, h           Shows a list of commands or help for one command\n\nGLOBAL OPTIONS:\n   --quiet, -q        suppress progress bar and log output (default: false) [$TRIVY_QUIET]\n   --debug, -d        debug mode (default: false) [$TRIVY_DEBUG]\n   --cache-dir value  cache directory (default: \u0026quot;/Users/faheem/Library/Caches/trivy\u0026quot;) [$TRIVY_CACHE_DIR]\n   --help, -h         show help (default: false)\n   --version, -v      print the version (default: false)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhen you run a scan, trivy will automatically download the vulnerabilities database and cache it for 12 hours. The database can also be downloaded separately if required.\u003c/p\u003e\n\u003cp\u003eLet\u0026rsquo;s take \u003ccode\u003etrivy\u003c/code\u003e for a spin and see it in action.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003etrivy image node:8-alpine\n\u003c/code\u003e\u003c/pre\u003e\n\u003cfigure class="wide"\u003e\n  \u003cimg class="img-fluid lazyload blur-up" data-sizes="auto" src="/blog/trivy-intro/trivy-scan-cli_huabd21dc3cd28384b4481f931a262a2bd_572718_20x0_resize_box_2.png" data-srcset="https://foreops.com/blog/trivy-intro/trivy-scan-cli_huabd21dc3cd28384b4481f931a262a2bd_572718_900x0_resize_box_2.png 900w,https://foreops.com/blog/trivy-intro/trivy-scan-cli_huabd21dc3cd28384b4481f931a262a2bd_572718_800x0_resize_box_2.png 800w,https://foreops.com/blog/trivy-intro/trivy-scan-cli_huabd21dc3cd28384b4481f931a262a2bd_572718_700x0_resize_box_2.png 700w,https://foreops.com/blog/trivy-intro/trivy-scan-cli_huabd21dc3cd28384b4481f931a262a2bd_572718_600x0_resize_box_2.png 600w,https://foreops.com/blog/trivy-intro/trivy-scan-cli_huabd21dc3cd28384b4481f931a262a2bd_572718_500x0_resize_box_2.png 500w" width="2308" height="1502" alt="trivy image node:8-alpine"\u003e\n  \u003cnoscript\u003e\u003cimg class="img-fluid" sizes="100vw" srcset="https://foreops.com/blog/trivy-intro/trivy-scan-cli_huabd21dc3cd28384b4481f931a262a2bd_572718_900x0_resize_box_2.png 900w,https://foreops.com/blog/trivy-intro/trivy-scan-cli_huabd21dc3cd28384b4481f931a262a2bd_572718_800x0_resize_box_2.png 800w,https://foreops.com/blog/trivy-intro/trivy-scan-cli_huabd21dc3cd28384b4481f931a262a2bd_572718_700x0_resize_box_2.png 700w,https://foreops.com/blog/trivy-intro/trivy-scan-cli_huabd21dc3cd28384b4481f931a262a2bd_572718_600x0_resize_box_2.png 600w,https://foreops.com/blog/trivy-intro/trivy-scan-cli_huabd21dc3cd28384b4481f931a262a2bd_572718_500x0_resize_box_2.png 500w" src="/blog/trivy-intro/trivy-scan-cli.png" width="2308" height="1502" alt="trivy image node:8-alpine"\u003e\u003c/noscript\u003e\n  \u003cfigcaption class="figure-caption"\u003eTrivy Scan Report\u003c/figcaption\u003e\n\u003c/figure\u003e\n\n\u003cp\u003e\u003ccode\u003enode:11-alpine\u003c/code\u003e seems to have several security vulnerabilities, including a few CRITICAL and HIGH. However, all of them are identified in the underlined \u003ccode\u003eAlpine 3.9.4\u003c/code\u003e operating system since we have not deployed any custom applications inside the container. Trivy can differentiate between OS and application dependency base vulnerabilities.\u003c/p\u003e\n\u003cp\u003eBy default, Trivy generates a tabular output on the CLI, but it supports templating, and you can generate reports in multiple formats including HTML file type. Let\u0026rsquo;s create an HTML report for the last run.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ewget https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/html.tpl\ntrivy image --format template --template @./html.tpl -o report.html node:11-alpine\n\u003c/code\u003e\u003c/pre\u003e\n\u003cfigure class="wide"\u003e\n  \u003cimg class="img-fluid lazyload blur-up" data-sizes="auto" src="/blog/trivy-intro/trivy-scan-html_hu2bc134aca7c82d159ae67a90a3a688cc_960235_20x0_resize_box_2.png" data-srcset="https://foreops.com/blog/trivy-intro/trivy-scan-html_hu2bc134aca7c82d159ae67a90a3a688cc_960235_900x0_resize_box_2.png 900w,https://foreops.com/blog/trivy-intro/trivy-scan-html_hu2bc134aca7c82d159ae67a90a3a688cc_960235_800x0_resize_box_2.png 800w,https://foreops.com/blog/trivy-intro/trivy-scan-html_hu2bc134aca7c82d159ae67a90a3a688cc_960235_700x0_resize_box_2.png 700w,https://foreops.com/blog/trivy-intro/trivy-scan-html_hu2bc134aca7c82d159ae67a90a3a688cc_960235_600x0_resize_box_2.png 600w,https://foreops.com/blog/trivy-intro/trivy-scan-html_hu2bc134aca7c82d159ae67a90a3a688cc_960235_500x0_resize_box_2.png 500w" width="2618" height="1640" alt="trivy image node:8-alpine"\u003e\n  \u003cnoscript\u003e\u003cimg class="img-fluid" sizes="100vw" srcset="https://foreops.com/blog/trivy-intro/trivy-scan-html_hu2bc134aca7c82d159ae67a90a3a688cc_960235_900x0_resize_box_2.png 900w,https://foreops.com/blog/trivy-intro/trivy-scan-html_hu2bc134aca7c82d159ae67a90a3a688cc_960235_800x0_resize_box_2.png 800w,https://foreops.com/blog/trivy-intro/trivy-scan-html_hu2bc134aca7c82d159ae67a90a3a688cc_960235_700x0_resize_box_2.png 700w,https://foreops.com/blog/trivy-intro/trivy-scan-html_hu2bc134aca7c82d159ae67a90a3a688cc_960235_600x0_resize_box_2.png 600w,https://foreops.com/blog/trivy-intro/trivy-scan-html_hu2bc134aca7c82d159ae67a90a3a688cc_960235_500x0_resize_box_2.png 500w" src="/blog/trivy-intro/trivy-scan-html.png" width="2618" height="1640" alt="trivy image node:8-alpine"\u003e\u003c/noscript\u003e\n  \u003cfigcaption class="figure-caption"\u003eTrivy Scan HTML Report\u003c/figcaption\u003e\n\u003c/figure\u003e\n\n\u003ch3 id="jenkins-integration"\u003eJenkins Integration\u003c/h3\u003e\n\u003cp\u003eLet\u0026rsquo;s add a scanning feature in our \u003ccode\u003eJenkinsfile\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-jenkinsfile"\u003e...\n        stage(\'Scan\') {\n            steps {\n                // Install trivy\n                sh \'curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin v0.18.3\'\n                sh \'curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/html.tpl \u0026gt; html.tpl\'\n\n                // Scan all vuln levels\n                sh \'mkdir -p reports\'\n                sh \'trivy filesystem --ignore-unfixed --vuln-type os,library --format template --template \u0026quot;@html.tpl\u0026quot; -o reports/nodjs-scan.html ./nodejs\'\n                publishHTML target : [\n                    allowMissing: true,\n                    alwaysLinkToLastBuild: true,\n                    keepAll: true,\n                    reportDir: \'reports\',\n                    reportFiles: \'nodjs-scan.html\',\n                    reportName: \'Trivy Scan\',\n                    reportTitles: \'Trivy Scan\'\n                ]\n\n                // Scan again and fail on CRITICAL vulns\n                sh \'trivy filesystem --ignore-unfixed --vuln-type os,library --exit-code 1 --severity CRITICAL ./nodejs\'\n\n            }\n...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cfigure class="wide"\u003e\n  \u003cimg class="img-fluid lazyload blur-up" data-sizes="auto" src="/blog/trivy-intro/trivy-scan-jenkins_hu09fc35e574777a6d796d9db5b7b061b2_599144_20x0_resize_box_2.png" data-srcset="https://foreops.com/blog/trivy-intro/trivy-scan-jenkins_hu09fc35e574777a6d796d9db5b7b061b2_599144_900x0_resize_box_2.png 900w,https://foreops.com/blog/trivy-intro/trivy-scan-jenkins_hu09fc35e574777a6d796d9db5b7b061b2_599144_800x0_resize_box_2.png 800w,https://foreops.com/blog/trivy-intro/trivy-scan-jenkins_hu09fc35e574777a6d796d9db5b7b061b2_599144_700x0_resize_box_2.png 700w,https://foreops.com/blog/trivy-intro/trivy-scan-jenkins_hu09fc35e574777a6d796d9db5b7b061b2_599144_600x0_resize_box_2.png 600w,https://foreops.com/blog/trivy-intro/trivy-scan-jenkins_hu09fc35e574777a6d796d9db5b7b061b2_599144_500x0_resize_box_2.png 500w" width="2233" height="1773" alt="trivy image node:8-alpine"\u003e\n  \u003cnoscript\u003e\u003cimg class="img-fluid" sizes="100vw" srcset="https://foreops.com/blog/trivy-intro/trivy-scan-jenkins_hu09fc35e574777a6d796d9db5b7b061b2_599144_900x0_resize_box_2.png 900w,https://foreops.com/blog/trivy-intro/trivy-scan-jenkins_hu09fc35e574777a6d796d9db5b7b061b2_599144_800x0_resize_box_2.png 800w,https://foreops.com/blog/trivy-intro/trivy-scan-jenkins_hu09fc35e574777a6d796d9db5b7b061b2_599144_700x0_resize_box_2.png 700w,https://foreops.com/blog/trivy-intro/trivy-scan-jenkins_hu09fc35e574777a6d796d9db5b7b061b2_599144_600x0_resize_box_2.png 600w,https://foreops.com/blog/trivy-intro/trivy-scan-jenkins_hu09fc35e574777a6d796d9db5b7b061b2_599144_500x0_resize_box_2.png 500w" src="/blog/trivy-intro/trivy-scan-jenkins.png" width="2233" height="1773" alt="trivy image node:8-alpine"\u003e\u003c/noscript\u003e\n  \u003cfigcaption class="figure-caption"\u003eTrivy Scan HTML Report\u003c/figcaption\u003e\n\u003c/figure\u003e\n\n\u003cp\u003eThe script downloads and runs the scanner on a \u003ca href="https://github.com/faheem556/funfact"\u003enodejs\u003c/a\u003e application path. It runs the scan twice, the second time from the previous cache, and fails the build if it discovers are any CRITICAL vulnerabilities. Finally, the report to the pipeline using \u003ca href="https://plugins.jenkins.io/htmlpublisher/"\u003eHTML Publisher\u003c/a\u003e plugin.\u003c/p\u003e\n\u003cp\u003eYou can manage false positives through \u003ca href="https://aquasecurity.github.io/trivy/v0.18.3/examples/filter/#by-vulnerability-ids"\u003e\u003ccode\u003e.trivyignore\u003c/code\u003e\u003c/a\u003e file. So you can check in your \u003ccode\u003e.trivyignore\u003c/code\u003e file and the scan step in Jenkins pipeline will pick it up automatically.\u003c/p\u003e\n\u003cp\u003eTrivy is a fast, lightweight, and user-friendly scanner that can easily integrate in any environment.\u003c/p\u003e\n\u003cp\u003eFurther Reading:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href="https://en.wikipedia.org/wiki/Shift-left_testing"\u003ehttps://en.wikipedia.org/wiki/Shift-left_testing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href="https://aquasecurity.github.io/trivy/v0.18.3/"\u003ehttps://aquasecurity.github.io/trivy/v0.18.3/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href="https://github.com/aquasecurity/trivy"\u003ehttps://github.com/aquasecurity/trivy\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href="https://aquasecurity.github.io/trivy/v0.18.3/comparison/"\u003ehttps://aquasecurity.github.io/trivy/v0.18.3/comparison/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href="https://aquasecurity.github.io/trivy/v0.18.3/air-gap/"\u003ehttps://aquasecurity.github.io/trivy/v0.18.3/air-gap/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href="https://hub.docker.com/r/aquasec/trivy"\u003ehttps://hub.docker.com/r/aquasec/trivy\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n'},{id:1,href:"/blog/terraform-intro/",title:"Introduction to Terraform",description:"Get started with terraform, learn basics, and write your first terraform file.",content:'\u003cfigure class="wide"\u003e\n  \u003cimg class="img-fluid lazyload blur-up" data-sizes="auto" src="/blog/terraform-intro/terraform-logo_hu8a1f794165927694df1b99ba38ab54b2_38240_20x0_resize_box_2.png" data-srcset="https://foreops.com/blog/terraform-intro/terraform-logo_hu8a1f794165927694df1b99ba38ab54b2_38240_900x0_resize_box_2.png 900w,https://foreops.com/blog/terraform-intro/terraform-logo_hu8a1f794165927694df1b99ba38ab54b2_38240_800x0_resize_box_2.png 800w,https://foreops.com/blog/terraform-intro/terraform-logo_hu8a1f794165927694df1b99ba38ab54b2_38240_700x0_resize_box_2.png 700w,https://foreops.com/blog/terraform-intro/terraform-logo_hu8a1f794165927694df1b99ba38ab54b2_38240_600x0_resize_box_2.png 600w,https://foreops.com/blog/terraform-intro/terraform-logo_hu8a1f794165927694df1b99ba38ab54b2_38240_500x0_resize_box_2.png 500w" width="1470" height="635" alt="Introduction to Terraform"\u003e\n  \u003cnoscript\u003e\u003cimg class="img-fluid" sizes="100vw" srcset="https://foreops.com/blog/terraform-intro/terraform-logo_hu8a1f794165927694df1b99ba38ab54b2_38240_900x0_resize_box_2.png 900w,https://foreops.com/blog/terraform-intro/terraform-logo_hu8a1f794165927694df1b99ba38ab54b2_38240_800x0_resize_box_2.png 800w,https://foreops.com/blog/terraform-intro/terraform-logo_hu8a1f794165927694df1b99ba38ab54b2_38240_700x0_resize_box_2.png 700w,https://foreops.com/blog/terraform-intro/terraform-logo_hu8a1f794165927694df1b99ba38ab54b2_38240_600x0_resize_box_2.png 600w,https://foreops.com/blog/terraform-intro/terraform-logo_hu8a1f794165927694df1b99ba38ab54b2_38240_500x0_resize_box_2.png 500w" src="/blog/terraform-intro/terraform-logo.png" width="1470" height="635" alt="Introduction to Terraform"\u003e\u003c/noscript\u003e\n  \n\u003c/figure\u003e\n\n\u003cp\u003eCloud vendors provide their own scripting languages for infrastructure management, such as AWS\u0026rsquo;s Cloud Formation or Azure\u0026rsquo;s Resource Manager Templates, but scripting with those can easily get complicated, brittle, and hard to maintain. Terraform uses the simple yet powerful HashiCorp Configuration Language (HCL) which can be scaled easily to an entire enterprise without the side-effects. Terraform has been embraced across the industry and has also been gaining favor with major cloud providers. Check out Azure\u0026rsquo;s \u003ca href="https://docs.microsoft.com/en-us/azure/azure-resource-manager/bicep/overview"\u003eBicep project\u003c/a\u003e or Google Cloud\u0026rsquo;s recent \u003ca href="https://cloud.google.com/blog/products/management-tools/private-catalog-for-google-cloud-marketplace-supports-terraform"\u003eannouncement\u003c/a\u003e to support Terraform for Marketplace Private Catalogs.\u003c/p\u003e\n\u003cp\u003eTerraform not only works across cloud, but its vast ecosystem of plugins also covers on-premises virtualization systems or private clouds such as \u003ca href="https://registry.terraform.io/providers/hashicorp/vsphere/latest"\u003evSphere\u003c/a\u003e, \u003ca href="https://registry.terraform.io/providers/nutanix/nutanix/latest"\u003eNutanix\u003c/a\u003e, \u003ca href="https://registry.terraform.io/providers/CiscoDevNet/aci/latest"\u003eCisco ACI\u003c/a\u003e, \u003ca href="https://registry.terraform.io/providers/HewlettPackard/oneview/latest"\u003eHPE OneView\u003c/a\u003e and others. You get more milage out of Terraform compared to other tooling. It also works with common shared services such as \u003ca href="https://registry.terraform.io/providers/F5Networks/bigip/latest"\u003eF5 BigIP\u003c/a\u003e load-balancers, \u003ca href="https://registry.terraform.io/providers/infobloxopen/infoblox/latest"\u003eInfoblox\u003c/a\u003e Grid, Microsoft \u003ca href="https://registry.terraform.io/providers/hashicorp/ad/latest"\u003eActive Directory\u003c/a\u003e, and others. Additionally, it can be extended through its \u003ca href="https://github.com/hashicorp/terraform-plugin-sdk"\u003eplugin SDK\u003c/a\u003e if needed. Remeber to check out the \u003ca href="https://registry.terraform.io/"\u003eTerraform Registry\u003c/a\u003e and colloborate with existing open-source community before you build your own plugins.\u003c/p\u003e\n\u003cp\u003eIn essence, Terraform manages the entire life-cycle of your infrastructure. It does not, however, replace your VM configuration management tooling. Once your infrastructure is up and running, you can switch over to your configuration management software and apply your configurations, recipes, or playbooks. It integrates nicely with push or pull-based configuration tools such as Ansible, Chef, Puppet, or others. Alternatively, you don\u0026rsquo;t need any configuration management if you design your infrastructure to be immutable and be replaced instead of in-place updates.\u003c/p\u003e\n\u003cp\u003eLet\u0026rsquo;s take Terraform for a spin and write some HCL.\u003c/p\u003e\n\u003ch2 id="installation"\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eTerraform comes as a single binary that can be installed on a variety of operating systems and CPU architectures. Since I work on a Mac, I am downloading the \u003ccode\u003edarwin\u003c/code\u003e binary.\u003c/p\u003e\n\u003cp\u003e\u003ca href="https://www.terraform.io/downloads.html"\u003eDownload Terraform\u003c/a\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ewget https://releases.hashicorp.com/terraform/1.0.0/terraform_1.0.0_darwin_amd64.zip\nunzip terraform*\nsudo mv terraform /usr/local/bin\nterraform --version\n\n  Terraform v1.0.0\n  on darwin_amd64\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="getting-started"\u003eGetting Started\u003c/h2\u003e\n\u003cp\u003eTerraform HFCL files have \u003ccode\u003e.tf\u003c/code\u003e file extension. Let\u0026rsquo;s create our first file, \u003ccode\u003emain.tf\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-tf"\u003eresource \u0026quot;random_password\u0026quot; \u0026quot;admin_password\u0026quot; {\n  length           = 16\n  special          = true\n  override_special = \u0026quot;_%@\u0026quot;\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd we are done! The code above will create a random password. We use the following three commands to run this code.\u003c/p\u003e\n\u003ch3 id="1-initialize"\u003e1. Initialize\u003c/h3\u003e\n\u003cp\u003eBefore we run our script, we have to initialize the \u0026ldquo;backend\u0026rdquo; and download the referenced plugins.  Let\u0026rsquo;s look into these quickly:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eBackend\u003c/em\u003e is where Terraform stores it state. After every code run, Terraform stores the configuration and the result in a state file. State can be stored locally or in remote backends. When working with a real environment, you have to share, version, backup, and secure your Terraform state and remote backends are ideal. However, since we have not configured any remote backend, the Terraform will create the state locally.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eWe are using the \u003ca href="https://registry.terraform.io/providers/hashicorp/random/latest/docs/resources/password"\u003e\u003ccode\u003erandom_password\u003c/code\u003e\u003c/a\u003e \u003cem\u003eplugin\u003c/em\u003e to create our password. This plugin is provided by HashiCorp and is available through their public registry.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003e$ terraform init\nInitializing the backend...\n\nInitializing provider plugins...\n- Finding latest version of hashicorp/random...\n- Installing hashicorp/random v3.1.0...\n- Installed hashicorp/random v3.1.0 (self-signed, key ID 34365D9472D7468F)\n\nPartner and community providers are signed by their developers.\nIf you\'\'d like to know more about provider signing, you can read about it here:\nhttps://www.terraform.io/docs/cli/plugins/signing.html\n\nTerraform has created a lock file .terraform.lock.hcl to record the provider\nselections it made above. Include this file in your version control repository\nso that Terraform can guarantee to make the same selections by default when\nyou run \u0026quot;terraform init\u0026quot; in the future.\n\nTerraform has been successfully initialized!\n\nYou may now begin working with Terraform. Try running \u0026quot;terraform plan\u0026quot; to see\nany changes that are required for your infrastructure. All Terraform commands\nshould now work.\n\nIf you ever set or change modules or backend configuration for Terraform,\nrerun this command to reinitialize your working directory. If you forget, other\ncommands will detect it and remind you to do so if necessary.\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe logs from the \u003ccode\u003einit\u003c/code\u003e command are pretty descriptive. Let\u0026rsquo;s see what files are created in our directory.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003e$ ls -a\n.terraform          .terraform.lock.hcl main.tf\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ccode\u003e.terraform\u003c/code\u003e is the folder where the plugins are downloaded. This folder is auto-generated and contains the binary files, it should not be included in the version control system.\u003c/p\u003e\n\u003ch3 id="2-plan"\u003e2. Plan\u003c/h3\u003e\n\u003cp\u003eThe second step is to list the changes the script is going to make. Since this is our first time running this code, this step is not as helpful. However, it will be beneficial when you make changes to any existing infrastructure.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003e$ terrraform plan\n\nAn execution plan has been generated and is shown below.\nResource actions are indicated with the following symbols:\n  + create\n\nTerraform will perform the following actions:\n\n  # random_password.admin_password will be created\n  + resource \u0026quot;random_password\u0026quot; \u0026quot;admin_password\u0026quot; {\n      + id               = (known after apply)\n      + length           = 16\n      + lower            = true\n      + min_lower        = 0\n      + min_numeric      = 0\n      + min_special      = 0\n      + min_upper        = 0\n      + number           = true\n      + override_special = \u0026quot;_%@\u0026quot;\n      + result           = (sensitive value)\n      + special          = true\n      + upper            = true\n    }\n\nPlan: 1 to add, 0 to change, 0 to destroy.\n\n------------------------------------------------------------------------\n\nNote: You didn\'t specify an \u0026quot;-out\u0026quot; parameter to save this plan, so Terraform\ncan\'t guarantee that exactly these actions will be performed if\n\u0026quot;terraform apply\u0026quot; is subsequently run.\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe are adding one new resource, perfec! So let\u0026rsquo;s apply these changes now.\u003c/p\u003e\n\u003ch3 id="3-apply"\u003e3. Apply\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003e$ terraform apply\n\nAn execution plan has been generated and is shown below.\nResource actions are indicated with the following symbols:\n  + create\n\nTerraform will perform the following actions:\n\n  # random_password.admin_password will be created\n  + resource \u0026quot;random_password\u0026quot; \u0026quot;admin_password\u0026quot; {\n      + id               = (known after apply)\n      + length           = 16\n      + lower            = true\n      + min_lower        = 0\n      + min_numeric      = 0\n      + min_special      = 0\n      + min_upper        = 0\n      + number           = true\n      + override_special = \u0026quot;_%@\u0026quot;\n      + result           = (sensitive value)\n      + special          = true\n      + upper            = true\n    }\n\nPlan: 1 to add, 0 to change, 0 to destroy.\n\nDo you want to perform these actions?\n  Terraform will perform the actions described above.\n  Only \'yes\' will be accepted to approve.\n\n  Enter a value: yes\n\nrandom_password.admin_password: Creating...\nrandom_password.admin_password: Creation complete after 0s [id=none]\n\nApply complete! Resources: 1 added, 0 changed, 0 destroyed.\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTerraform \u003ccode\u003eapply\u003c/code\u003e command displays the planned changes one more time and prompts before applying these changes. We have successfully created the random password.\u003c/p\u003e\n\u003cp\u003eBut wait, where is the password we just created? The password is created and stored in the terraform state. You wouldn\u0026rsquo;t want to print the password to the screen, would you? Now, you can safely reference the password when creating another resource, such as a Virtual Machine, or store it in HashiCorp Vault by extending the HCL script.\u003c/p\u003e\n\u003cp\u003eFor our exercise, however, let\u0026rsquo;s look at the state file terraform created for us.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003e$ cat terraform.tfstate\n{\n  \u0026quot;version\u0026quot;: 4,\n  \u0026quot;terraform_version\u0026quot;: \u0026quot;0.14.6\u0026quot;,\n  \u0026quot;serial\u0026quot;: 1,\n  \u0026quot;lineage\u0026quot;: \u0026quot;77fd4a2d-351a-1700-e3d4-d74ebc9aabd8\u0026quot;,\n  \u0026quot;outputs\u0026quot;: {},\n  \u0026quot;resources\u0026quot;: [\n    {\n      \u0026quot;mode\u0026quot;: \u0026quot;managed\u0026quot;,\n      \u0026quot;type\u0026quot;: \u0026quot;random_password\u0026quot;,\n      \u0026quot;name\u0026quot;: \u0026quot;admin_password\u0026quot;,\n      \u0026quot;provider\u0026quot;: \u0026quot;provider[\\\u0026quot;registry.terraform.io/hashicorp/random\\\u0026quot;]\u0026quot;,\n      \u0026quot;instances\u0026quot;: [\n        {\n          \u0026quot;schema_version\u0026quot;: 0,\n          \u0026quot;attributes\u0026quot;: {\n            \u0026quot;id\u0026quot;: \u0026quot;none\u0026quot;,\n            \u0026quot;keepers\u0026quot;: null,\n            \u0026quot;length\u0026quot;: 16,\n            \u0026quot;lower\u0026quot;: true,\n            \u0026quot;min_lower\u0026quot;: 0,\n            \u0026quot;min_numeric\u0026quot;: 0,\n            \u0026quot;min_special\u0026quot;: 0,\n            \u0026quot;min_upper\u0026quot;: 0,\n            \u0026quot;number\u0026quot;: true,\n            \u0026quot;override_special\u0026quot;: \u0026quot;_%@\u0026quot;,\n            \u0026quot;result\u0026quot;: \u0026quot;DM4Skgcigxp@y3RX\u0026quot;,\n            \u0026quot;special\u0026quot;: true,\n            \u0026quot;upper\u0026quot;: true\n          },\n          \u0026quot;sensitive_attributes\u0026quot;: [],\n          \u0026quot;private\u0026quot;: \u0026quot;bnVsbA==\u0026quot;\n        }\n      ]\n    }\n  ]\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou can see that the password is stored in the state file as plain text. That is why you need to keep this file in a secure place. For added security, Terraform supports several remote backends that provide encryption at rest.\u003c/p\u003e\n\u003cp\u003eThat\u0026rsquo;s it for this post, in our next post we will create a virtual machine in AWS with some basic configuration. Stay tuned.\u003c/p\u003e\n'},{id:2,href:"/blog/kubernetes-admission-control/",title:"Admission Control in Kubernetes",description:"Admission controllers are essential for security, governance, and configuration management in Kubernetes.",content:'\u003cp\u003eThey come in handy to implement or validate resource limits or ensure that the deployments are not using the \u0026ldquo;latest\u0026rdquo; image tags. For instance, you can restrict pods to pull container images from certain registries or disallow containers to run in privileged mode. In addition, admission controllers can enforce label naming conventions or add annotations, such as a cost center to objects.\u003c/p\u003e\n\u003cp\u003eThe admission controllers intercept requests made to the API server before the persistence of the object. The API server passes the request to admission controllers after successfully authenticating and authorizing the request. After that, Kubernetes persists everything to \u003ca href="https://etcd.io/"\u003eetcd\u003c/a\u003e datastore if admission controllers allow it. etcd is a key/value datastore that stores the current configuration, objects, metadata, and the actual and desired state of the cluster. Kubernetes watches the etcd database for updates and makes any changes if the actual and desired states diverge. That is why admission controllers sit between the persistence of the request and only admitted requests are allowed to change the desired state of the cluster.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-go"\u003e// DefaultOffAdmissionPlugins get admission plugins off by default for kube-apiserver.\nfunc DefaultOffAdmissionPlugins() sets.String {\n  defaultOnPlugins := sets.NewString(\n    lifecycle.PluginName,                    // NamespaceLifecycle\n    limitranger.PluginName,                  // LimitRanger\n    serviceaccount.PluginName,               // ServiceAccount\n    setdefault.PluginName,                   // DefaultStorageClass\n    resize.PluginName,                       // PersistentVolumeClaimResize\n    defaulttolerationseconds.PluginName,     // DefaultTolerationSeconds\n    mutatingwebhook.PluginName,              // MutatingAdmissionWebhook\n    validatingwebhook.PluginName,            // ValidatingAdmissionWebhook\n    resourcequota.PluginName,                // ResourceQuota\n    storageobjectinuseprotection.PluginName, // StorageObjectInUseProtection\n    podpriority.PluginName,                  // PodPriority\n    nodetaint.PluginName,                    // TaintNodesByCondition\n    runtimeclass.PluginName,                 // RuntimeClass\n    certapproval.PluginName,                 // CertificateApproval\n    certsigning.PluginName,                  // CertificateSigning\n    certsubjectrestriction.PluginName,       // CertificateSubjectRestriction\n    defaultingressclass.PluginName,          // DefaultIngressClass\n  )\n\n  return sets.NewString(AllOrderedPlugins...).Difference(defaultOnPlugins)\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ca href="https://github.com/kubernetes/kubernetes/blob/ea0764452222146c47ec826977f49d7001b0ea8c/pkg/kubeapiserver/options/plugins.go#L141"\u003eCode snippet\u003c/a\u003e from Kubernetes Project\u003c/p\u003e\n\u003ch4 id="monitoring"\u003eMonitoring\u003c/h4\u003e\n\u003cp\u003eAs several admission controllers are running,  the API server provides ways to monitor and troubleshoot admission webhooks, for instance, identify webhooks that reject API requests frequently and the reasons for rejection.\u003c/p\u003e\n\u003ch4 id="dynamic-admission-control"\u003eDynamic Admission Control\u003c/h4\u003e\n\u003cp\u003eIn addition, to the compiled-in admission plugins, custom admission plugins can be implemented as webhooks.  Webhooks are either mutating, validating, or both.  Mutating webhooks modify the objects in an API request, for instance, injecting sidecars into every pod. Validating webhooks validate objects sent to the API server, for example, limiting all replica sets to a minimum of 3.\u003c/p\u003e\n\u003ch5 id="idempotence"\u003eIdempotence\u003c/h5\u003e\n\u003cp\u003eThe API server can call an admission controller multiple times.  Idempotence is the property of certain operations in mathematics and computer science whereby they can be applied multiple times without changing the result beyond the initial application. For example, consider that if you are writing an idempotent script to add localhost to /etc/hosts file, you will only append localhost to /etc/hosts file if it does not already exist in the file. Otherwise, if the script added localhost every time it ran, you will have multiple localhost entries.\u003c/p\u003e\n\u003cp\u003eAn idempotent mutating admission webhook can successfully process an object it has already admitted and potentially modified. For example, let say there are two admission webhooks, AlwaysPulIlmage webhook and insert sidecar webhook.  AlwaysPullImage would be called twice, once for the pod object and then after the sidecar injection. As AlwaysPullImage applies to both. On the other hand, you would not want to inject the sidecar every time the API server calls the webhook insert sidecar webhook.\u003c/p\u003e\n\u003ch5 id="intercepting-all-versions-of-an-object"\u003eIntercepting all versions of an object\u003c/h5\u003e\n\u003cp\u003eAs Kubernetes supports multiple \u003ca href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.21/#-strong-api-groups-strong-"\u003eAPI groups/versions\u003c/a\u003e, you can set the .webhooks[].matchPolicy to either Exact or Equivalent when defining a webhook. When matchPolicy is Exact, a webhook would only intercept the request when there is an exact match and miss some if a different version modified the same object. It is best to use Equivalent to match all versions of an object; this ensures that admission controllers continue to work even when resources upgrade to newer versions.\u003c/p\u003e\n\u003cp\u003eThis example shows a validating webhook that intercepts modifications to deployments no matter the API group or version (matchPolicy: Equivalent) and intercepts all apps/v1 Deployment objects:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003eapiVersion: admissionregistration.k8s.io/v1\nkind: ValidatingWebhookConfiguration\n...\nwebhooks:\n- name: my-webhook.example.com\n  matchPolicy: Equivalent\n  rules:\n  - operations: [\u0026quot;CREATE\u0026quot;,\u0026quot;UPDATE\u0026quot;,\u0026quot;DELETE\u0026quot;]\n    apiGroups: [\u0026quot;apps\u0026quot;]\n    apiVersions: [\u0026quot;v1\u0026quot;]\n    resources: [\u0026quot;deployments\u0026quot;]\n    scope: \u0026quot;Namespaced\u0026quot;\n...\n...\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch5 id="availability"\u003eAvailability\u003c/h5\u003e\n\u003cp\u003eAdmission webhooks should evaluate objects, usually in a matter of milliseconds, to ensure that they do not increase latency to API requests. Additionally, you should specify a timeout value so that the request fails after the timeout expires if the webhook is not responding. The default timeout value is 10 seconds and must be between 1 to 30 seconds. Also, the webhook design should ensure high availability and performance; for instance, run several webhook backends behind a service in a cluster.\u003c/p\u003e\n\u003ch5 id="the-final-state-of-the-object"\u003eThe final state of the object\u003c/h5\u003e\n\u003cp\u003eWhen implementing a mutating webhook, you can verify the final state of the object by implementing a validating webhook since other webhooks can modify the object after being seen by your mutating webhook.\u003c/p\u003e\n\u003cp\u003eAvoiding deadlocks when running webhook backends on the same cluster\nDeadlocks can occur if a webhook running inside a cluster starts to intercept and reject its resources. For instance, if the node goes down, the scheduler would assign the pods to another node, and the deployment would go through the admission control again. You can run your webhook backend in a separate namespace and then \u003ca href="https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#matching-requests-namespaceselector"\u003eexclude\u003c/a\u003e that namespace.\u003c/p\u003e\n\u003ch5 id="side-effects"\u003eSide-effects\u003c/h5\u003e\n\u003cp\u003eWhen an API server sends an AdmissionReview \u0026ldquo;request\u0026rdquo; to a webhook for review, the webhook responds with an AdmissionReview \u0026ldquo;response.\u0026rdquo;\nThe webhook should only make changes to the AdmissionReview object passed to them without any out-of-band (\u003ca href="https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#side-effects"\u003eside-effects\u003c/a\u003e) changes.\nIf the webhook requires side effects during admission evaluation, it should not make any out-of-band changes if AdmissionReview \u0026ldquo;request\u0026rdquo; specifies that it is a dry run.\nThe API server does not persist dry-run requests; it processes and evaluates the request and returns the final object to the user. The API server only processes dry-run requests if admission controllers explicitly specify that they do not have any side-effects.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003e{\n  \u0026quot;apiVersion\u0026quot;: \u0026quot;admission.k8s.io/v1\u0026quot;,\n  \u0026quot;kind\u0026quot;: \u0026quot;AdmissionReview\u0026quot;,\n  \u0026quot;request\u0026quot;: {\n    # Random uid uniquely identifying this admission call\n    \u0026quot;uid\u0026quot;: \u0026quot;705ab4f5-6393-11e8-b7cc-42010a800002\u0026quot;,\n\n...\n...\n...\n    # dryRun indicates the API request is running in dry run mode and will not be persisted.\n    # Webhooks with side effects should avoid actuating those side effects when dryRun is true.\n    # See http://k8s.io/docs/reference/using-api/api-concepts/#make-a-dry-run-request for more details.\n    \u0026quot;dryRun\u0026quot;: false\n  }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAdmissionReview \u0026ldquo;request\u0026rdquo;\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003e{\n  \u0026quot;apiVersion\u0026quot;: \u0026quot;admission.k8s.io/v1\u0026quot;,\n  \u0026quot;kind\u0026quot;: \u0026quot;AdmissionReview\u0026quot;,\n  \u0026quot;response\u0026quot;: {\n    \u0026quot;uid\u0026quot;: \u0026quot;\u0026lt;value from request.uid\u0026gt;\u0026quot;,\n    \u0026quot;allowed\u0026quot;: true\n  }\n}\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAdmissionReview \u0026ldquo;response\u0026rdquo;\u003c/p\u003e\n\u003ch5 id="do-not-operate-in-the-kube-system-namespace"\u003eDo not operate in the kube-system namespace\u003c/h5\u003e\n\u003cp\u003eKubernetes manages its components in the kube-system namespace. Therefore, it would be best if you never ran typical workloads in this namespace.  If your webhook mutates or rejects requests in this namespace, it can lead to failure or strange behavior of the control plane.  You can exclude namespaces you do intend to operate in by using the \u003ca href="https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#matching-requests-namespaceselector"\u003enamespaceSelector\u003c/a\u003e.\u003c/p\u003e\n\u003ch4 id="key-takeaways"\u003eKey takeaways\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eAll requests to the API server pass through admission controllers and if successful persisted to the datastore like etcd.\u003c/li\u003e\n\u003cli\u003eAdmission has two distinct phases. In the first phase, only mutating admission plugins run. Mutating admission plugins may modify the object that they receive. In the second phase, only validating admission plugins run, and they do not modify the objects.\u003c/li\u003e\n\u003cli\u003eA plugin can be a validating plugin, mutating plugin, or both.\u003c/li\u003e\n\u003cli\u003eThe API server calls mutating admission webhooks one by one while it calls validating admission webhooks in parallel.\u003c/li\u003e\n\u003cli\u003eKubernetes enables a recommended set of around 17 admission plugins by default. Admission controllers are part of the API server binary.\u003c/li\u003e\n\u003cli\u003eIn addition, to the compiled-in admission plugins, custom admission plugins can be implemented as webhooks.\u003c/li\u003e\n\u003cli\u003eThe API server can call an admission controller multiple times and should be idempotent.\u003c/li\u003e\n\u003cli\u003eIt is best to set matchPolicy to Equivalent to match all versions of an object; this ensures that admission controllers continue to work even when resources upgrade to newer versions.\u003c/li\u003e\n\u003cli\u003eAdmission webhooks should evaluate objects, usually in a matter of milliseconds, to ensure that they do not increase latency to API requests.\u003c/li\u003e\n\u003cli\u003eYou should run your webhook backend in a separate namespace and then exclude that namespace to avoid deadlocks.\u003c/li\u003e\n\u003cli\u003eWhen an API server sends an AdmissionReview \u0026ldquo;request\u0026rdquo; to a webhook for review, the webhook responds with an AdmissionReview \u0026ldquo;response.\u0026rdquo; The webhook should only make changes to the AdmissionReview object passed to them without any out-of-band (side-effects) changes.\u003c/li\u003e\n\u003cli\u003eDo not operate in the kube-system namespace.\u003c/li\u003e\n\u003c/ul\u003e\n'},{id:3,href:"/blog/kubernetes-authorization/",title:"Kubernetes Authorization",description:"Authorization grants you access permission for resources in the cluster. A Kubernetes cluster will only authorize your requests after authentication.",content:'\u003cp\u003eKubernetes API Server is implemented as a RESTful API service and acts as a front end to its control plane. \u003ca href="https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm"\u003eREST\u003c/a\u003e is an architecture style developed by \u003ca href="http://www.ics.uci.edu/~fielding/"\u003eRoy Thomas Fielding\u003c/a\u003e. One of the guiding principles of REST is statelessness. Each request from a client must contain all the information required to complete the request, including authentication and authorization. The RESTful API implementation in Kubernetes makes it compatible with existing on-prem or cloud access systems.\u003c/p\u003e\n\u003cp\u003eThe API server denies all requests by default. It only authorizes a request when all parts of the request match a policy. You can configure multiple authorization modes. In such a case, it will evaluate all authorization modes one by one until it finds the first authorizer that approves or denies the request, and it immediately returns the result ignoring the rest of the authorizers.\u003c/p\u003e\n\u003cp\u003eKubernetes supports several authorization modes:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRBAC\u003c/li\u003e\n\u003cli\u003eNode\u003c/li\u003e\n\u003cli\u003eABAC\u003c/li\u003e\n\u003cli\u003eWebhook\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id="rbac"\u003eRBAC\u003c/h4\u003e\n\u003cp\u003eRole based access control (RBAC), formalized by \u003ca href="https://csrc.nist.gov/publications/detail/conference-paper/1992/10/13/role-based-access-controls"\u003eDavid Ferraiolo and Rick Kuhn\u003c/a\u003e, has been widely adopted by organizations to grant access to systems based on a person\u0026rsquo;s role within the organization or team.  In Kubernetes, roles have a set of permissions tied to them. The permissions match verbs with resources; for instance,  create, get, update, patch, delete with resources pods, services, nodes, etc. The permissions can have a namespace or cluster-wide scope. The API requests made to \u003ccode\u003e/api/v1/...\u003c/code\u003e or \u003ccode\u003e/apis/\u0026lt;group\u0026gt;/\u0026lt;version\u0026gt;/...\u003c/code\u003e are considered resource requests. Any other requests are \u0026ldquo;non-resource-requests.\u0026rdquo; They use the HTTP method as the lower case verb. For instance, the GET method becomes the get verb.\u003c/p\u003e\n\u003cp\u003eRBAC authorization uses the \u003ccode\u003erbac.authorization.k8s.io\u003c/code\u003e API group to drive authorization decisions, allowing you to configure policies through the Kubernetes API dynamically.\u003c/p\u003e\n\u003cp\u003eThere are no \u0026ldquo;deny\u0026rdquo; rules in RBAC roles as they are purely additive. An excellent way to think about it is that users, groups, or service accounts are denied access to cluster resources by default, and you explicitly grant access to them. A role does not specify a user or group of users; you essentially assign roles to users or groups, thus creating a binding.  In Kubernetes, you define your RBAC permissions using the following objects:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003e\u003cstrong\u003eClusterRole\u003c/strong\u003e\u003c/em\u003e or \u003cem\u003e\u003cstrong\u003eRole\u003c/strong\u003e\u003c/em\u003e contains a set of resources and operations that a user or group of users can perform on them. If you want to define a role within a namespace, use the Role object; if you\u0026rsquo;re going to define a role cluster-wide, use a ClusterRole.\u003c/li\u003e\n\u003cli\u003e\u003cem\u003e\u003cstrong\u003eClusterRoleBinding\u003c/strong\u003e\u003c/em\u003e or \u003cem\u003e\u003cstrong\u003eRoleBinding\u003c/strong\u003e\u003c/em\u003e assigns (binds) a ClusterRole or Role to a user or group of users. A ClusterRoleBinding only is used with a ClusterRole. RoleBinding, on the other hand, will work with either ClusterRole or Role.\nClusterRole allows you to control permissions cluster-wide and have several uses. For instance, grant permissions across all namespaces (for example, all pods cluster-wise), within namespaces, or cluster-wide resources, like nodes. In addition, ClusterRole can be used to control access to non-resources API endpoints, such as \u003ccode\u003e/healthz\u003c/code\u003e. See \u003ca href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/"\u003eUsing RBAC Authorization\u003c/a\u003e for various examples.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id="node"\u003eNode\u003c/h4\u003e\n\u003cp\u003eNode authorization mode in Kubernetes authorizes API requests made by kubelets running on nodes. The kubelet is the primary \u0026ldquo;node agent\u0026rdquo; that runs on each node and ensures that the containers are running and healthy.  The node authorizer enables kubelets to perform read, write, and authentication-related operations.\u003c/p\u003e\n\u003ch4 id="abac"\u003eABAC\u003c/h4\u003e\n\u003cp\u003eAttribute-based access control (ABAC) is an access control model that consists of rules based on the attributes of the subject (user or group), attributes of the object (pods, namespace), action (read, write), and environmental conditions (nonResourcePath: \u003ccode\u003e/version\u003c/code\u003e). In addition, ABAC policies express a true/false set that can evaluate many attributes.  Role-based Access Control (RBAC) is a preferred authorization method over the legacy ABAC in Kubernetes. Managing ABAC policies requires one to log into the node to update the file containing ABAC policies. In contrast, administrators can manage RBAC through Kubernetes API.\u003c/p\u003e\n\u003cp\u003eIn the following example, Bob can read pods in the \u0026ldquo;projectCaribou\u0026rdquo; namespace.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003e{\n  \u0026quot;apiVersion\u0026quot;: \u0026quot;abac.authorization.kubernetes.io/v1beta1\u0026quot;,\n  \u0026quot;kind\u0026quot;: \u0026quot;Policy\u0026quot;,\n  \u0026quot;spec\u0026quot;:\n    {\n      \u0026quot;user\u0026quot;: \u0026quot;bob\u0026quot;,\n      \u0026quot;namespace\u0026quot;: \u0026quot;projectCaribou\u0026quot;,\n      \u0026quot;resource\u0026quot;: \u0026quot;pods\u0026quot;,\n      \u0026quot;readonly\u0026quot;: true\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4 id="webhook"\u003eWebhook\u003c/h4\u003e\n\u003cp\u003eA webhook is a callback over HTTP. A callback is usually a function passed to another function. The first function calls this function (callback) after it completes.  A more intuitive name for the callback is the \u0026ldquo;call-after\u0026rdquo; function. An application implementing webhooks will usually POST  a message to a URL when certain events occur. For examples, when Webhook mode is active, Kubernetes will query an outside RESTful service to determine user privileges. Here is an example of a request the API Server would POST to the remote service for an authorization decision.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003e{\n  \u0026quot;apiVersion\u0026quot;: \u0026quot;authorization.k8s.io/v1beta1\u0026quot;,\n  \u0026quot;kind\u0026quot;: \u0026quot;SubjectAccessReview\u0026quot;,\n  \u0026quot;spec\u0026quot;: {\n    \u0026quot;resourceAttributes\u0026quot;: {\n      \u0026quot;namespace\u0026quot;: \u0026quot;kittensandponies\u0026quot;,\n      \u0026quot;verb\u0026quot;: \u0026quot;get\u0026quot;,\n      \u0026quot;group\u0026quot;: \u0026quot;unicorn.example.org\u0026quot;,\n      \u0026quot;resource\u0026quot;: \u0026quot;pods\u0026quot;\n    },\n    \u0026quot;user\u0026quot;: \u0026quot;jane\u0026quot;,\n    \u0026quot;group\u0026quot;: [\n      \u0026quot;group1\u0026quot;,\n      \u0026quot;group2\u0026quot;\n    ]\n  }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe remote service would respond and fill the \u0026lsquo;status\u0026rsquo; field of the request to allow or disallow the request.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003e{\n  \u0026quot;apiVersion\u0026quot;: \u0026quot;authorization.k8s.io/v1beta1\u0026quot;,\n  \u0026quot;kind\u0026quot;: \u0026quot;SubjectAccessReview\u0026quot;,\n  \u0026quot;status\u0026quot;: {\n    \u0026quot;allowed\u0026quot;: false,\n    \u0026quot;denied\u0026quot;: true,\n    \u0026quot;reason\u0026quot;: \u0026quot;user does not have read access to the namespace\u0026quot;\n  }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4 id="key-takeaways"\u003eKey Takeaways\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eOne of the guiding principles of REST is statelessness. Each request from a client must contain all the information required to complete the request, including authentication and authorization.\u003c/li\u003e\n\u003cli\u003eThe API server denies all requests by default. It only authorizes a request when all parts of the request match a policy.\u003c/li\u003e\n\u003cli\u003eKubernetes will evaluate all configured authorization modes and return immediately as soon as it finds one that approves or denies the request and ignores the rest of the authorizers.\u003c/li\u003e\n\u003cli\u003eThere are no \u0026ldquo;deny\u0026rdquo; rules in RBAC roles as they are purely additive.  The users, groups, or service accounts are denied access to cluster resources by default, and you explicitly grant access to them.\u003c/li\u003e\n\u003cli\u003eA role does not specify a user or group of users; you essentially assign roles to users or groups, thus creating a binding.\u003c/li\u003e\n\u003cli\u003eNode authorization mode in Kubernetes authorizes API requests made by kubelets running on nodes.\u003c/li\u003e\n\u003cli\u003eAttribute-based access control (ABAC) is an access control model that consists of rules based on the attributes of the subject (user or group), attributes of the object (pods, namespace), action (read, write), and environmental conditions (nonResourcePath: \u0026ldquo;/version\u0026rdquo;).\u003c/li\u003e\n\u003cli\u003eManaging ABAC policies requires one to log into the node to update the file containing ABAC policies. In contrast, administrators can manage RBAC through Kubernetes API.\u003c/li\u003e\n\u003cli\u003eA webhook is a callback over HTTP. A callback is usually a function passed to another function. The first function calls this function (callback) after it completes; sometimes, it is called a \u0026ldquo;call-after\u0026rdquo; function.\u003c/li\u003e\n\u003cli\u003eWhen Webhook mode is active, Kubernetes will query an outside RESTful service to determine user privileges.\u003c/li\u003e\n\u003c/ul\u003e\n'},{id:4,href:"/blog/kubernetes-authentication/",title:"Kubernetes Authentication",description:"Authentication in Kubernetes is about verifying the identity of users and services.",content:'\u003cp\u003eThis post will discuss authentication methods for two types of accounts that access the Kubernetes cluster: users and machines. While cluster administrators and application developers require access to the cluster to manage and deploy applications respectively, machines, processes, and applications also need access to the cluster, which they obtain through the service accounts.\u003c/p\u003e\n\u003cfigure class="wide"\u003e\n  \u003cimg class="img-fluid lazyload blur-up" data-sizes="auto" src="/blog/kubernetes-authentication/kubernetes-authentication_hue38ed8ce16d10c8c4e617f6df2de1956_70091_20x0_resize_box_2.png" data-srcset="https://foreops.com/blog/kubernetes-authentication/kubernetes-authentication_hue38ed8ce16d10c8c4e617f6df2de1956_70091_900x0_resize_box_2.png 900w,https://foreops.com/blog/kubernetes-authentication/kubernetes-authentication_hue38ed8ce16d10c8c4e617f6df2de1956_70091_800x0_resize_box_2.png 800w,https://foreops.com/blog/kubernetes-authentication/kubernetes-authentication_hue38ed8ce16d10c8c4e617f6df2de1956_70091_700x0_resize_box_2.png 700w,https://foreops.com/blog/kubernetes-authentication/kubernetes-authentication_hue38ed8ce16d10c8c4e617f6df2de1956_70091_600x0_resize_box_2.png 600w,https://foreops.com/blog/kubernetes-authentication/kubernetes-authentication_hue38ed8ce16d10c8c4e617f6df2de1956_70091_500x0_resize_box_2.png 500w" width="1280" height="720" alt="Kubernetes Authentication"\u003e\n  \u003cnoscript\u003e\u003cimg class="img-fluid" sizes="100vw" srcset="https://foreops.com/blog/kubernetes-authentication/kubernetes-authentication_hue38ed8ce16d10c8c4e617f6df2de1956_70091_900x0_resize_box_2.png 900w,https://foreops.com/blog/kubernetes-authentication/kubernetes-authentication_hue38ed8ce16d10c8c4e617f6df2de1956_70091_800x0_resize_box_2.png 800w,https://foreops.com/blog/kubernetes-authentication/kubernetes-authentication_hue38ed8ce16d10c8c4e617f6df2de1956_70091_700x0_resize_box_2.png 700w,https://foreops.com/blog/kubernetes-authentication/kubernetes-authentication_hue38ed8ce16d10c8c4e617f6df2de1956_70091_600x0_resize_box_2.png 600w,https://foreops.com/blog/kubernetes-authentication/kubernetes-authentication_hue38ed8ce16d10c8c4e617f6df2de1956_70091_500x0_resize_box_2.png 500w" src="/blog/kubernetes-authentication/kubernetes-authentication.png" width="1280" height="720" alt="Kubernetes Authentication"\u003e\u003c/noscript\u003e\n  \u003cfigcaption class="figure-caption"\u003eKubernetes Authentication\u003c/figcaption\u003e\n\u003c/figure\u003e\n\n\u003ch3 id="user-authentication"\u003eUser Authentication\u003c/h3\u003e\n\u003cp\u003eKubernetes does not have objects which represent user accounts. Users do not log in, and there are no sessions or timeouts. Every request made to the API server is unique, and it contains everything that the API server requires to authenticate/authorize the request. There are many different authentication mechanisms to choose from based on suitability to specific types of implementation.\u003c/p\u003e\n\u003cp\u003eOne of the simplest methods is to use a static token file in CSV format with three required columns: token, user name, user uid, and an optional column for group names. The API server reads bearer tokens from this file which is specified as a command-line option. Updates to the file require access to the node running the API server. Every time the file changes, you have to restart the API server. However, this is not a recommended authentication method as the tokens can last forever.\u003c/p\u003e\n\u003cp\u003eUsers can also authenticate by presenting a certificate signed by the cluster\u0026rsquo;s certificate authority (CA). The user submits the certificate in the form of a Certificate Header or through the kubectl command. The API server reads the username (CN=devuser) and group name (O=engineering) from the \u0026lsquo;subject\u0026rsquo; line of the certificate. When using this method, the administrators are responsible for generating, revoking, and expiry of certificates.\u003c/p\u003e\n\u003cp\u003eMost of the time, OIDC (OpenID Connect) is used in a production or cloud environment. Users authenticate with their OIDC platform to get tokens. The administrators configure the API server to accept these tokens that contain identity information. It Is also important to note that Kubernetes does not connect to a user directory.\u003c/p\u003e\n\u003cp\u003eTwo more methods are available to use custom identity providers, authenticating proxy or authentication webhook. Authentication proxy used to integrate with LDAP, SAML, Kerberos, alternate x509 schemes, etc. HTTP headers specify a username, group, and any extra information about the user. On the API server, these headers are mapped to the required API server switches.\u003c/p\u003e\n\u003cp\u003eWebhook authentication allows users to generate tokens through the external service. The users use these tokens when authenticating with the API server. When a client starts to authenticate using a bearer token, the authentication webhook POSTs a JSON-serialized TokenReview object containing the token to the remote service. The remote service indicates success by updating a status field in the request. Usernames derived from various supported authentication identity providers must be unique cluster-wide.\u003c/p\u003e\n\u003ch3 id="machine-authentication"\u003eMachine Authentication\u003c/h3\u003e\n\u003cp\u003eThe Service Account controller manages service accounts inside namespaces. It creates a service account named \u0026ldquo;default\u0026rdquo; in all active namespaces. When a pod\u0026rsquo;s manifest does not specify a service account,  it will use the \u0026ldquo;default\u0026rdquo; service account in its namespace. Service accounts that do not belong to the kube-system namespace have no permissions. Applications access the API server using the service account specified in their pod. An excellent example of such an application is a Kubernetes dashboard that exists in a pod. It will use the service account to talk to the API server. Service accounts use credentials from secrets mounted into pods. Only one service account is per pod is used. Any required roles can be granted to service accounts as needed. Application-specific service accounts should be created and given permissions as needed.\u003c/p\u003e\n\u003cp\u003eWhen the API server creates a service account, it generates a token and stores it in a secret object. The API server then links this to the newly created service account. The token in secret is an authentication bearer token used to communicate with the API server. On pods creation, the secret is made available to the pod as a volume.\u003c/p\u003e\n\u003ch3 id="key-takeaways"\u003eKey Takeaways\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eAuthentication in Kubernetes is about verifying the identity of users (humans) and services (machines, processes, or applications).\nKubernetes does not have objects which represent user accounts. Users do not log in, and there are no sessions or timeouts.\u003c/li\u003e\n\u003cli\u003eYou do not connect Kubernetes to a user directory. Kubernetes supports several authentication mechanisms out of the box and provides support for custom authentication schemes.\u003c/li\u003e\n\u003cli\u003eUsernames derived from various supported authentication identity providers must be unique cluster-wide.\u003c/li\u003e\n\u003cli\u003eA service account named \u0026ldquo;default\u0026rdquo; exists in all active namespaces.\u003c/li\u003e\n\u003cli\u003eService accounts that do not belong to the kube-system namespace have no permissions.\u003c/li\u003e\n\u003cli\u003eService accounts use credentials from secrets mounted into pods. Each pod can use one service account only.\u003c/li\u003e\n\u003cli\u003eWhen you create pods, the secret in the service account is made available as a volume.\u003c/li\u003e\n\u003c/ul\u003e\n'},{id:5,href:"/blog/",title:"Blog",description:"The foreops blog.",content:""}];b.add(c),userinput.addEventListener('input',e,!0),suggestions.addEventListener('click',f,!0);function e(){var g=this.value,e=b.search(g,5),f=suggestions.childNodes,h=0,i=e.length,c;for(suggestions.classList.remove('d-none'),e.forEach(function(b){c=document.createElement('div'),c.innerHTML='<a href><span></span><span></span></a>',a=c.querySelector('a'),t=c.querySelector('span:first-child'),d=c.querySelector('span:nth-child(2)'),a.href=b.href,t.textContent=b.title,d.textContent=b.description,suggestions.appendChild(c)});f.length>i;)suggestions.removeChild(f[h])}function f(){while(suggestions.lastChild)suggestions.removeChild(suggestions.lastChild);return!1}})()